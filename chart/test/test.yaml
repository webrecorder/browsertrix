# test overrides
# --------------

crawler_browser_instances: 1

backend_workers: 2

frontend_memory: 32Mi

# base cpu for for 1 browser
crawler_cpu: 1100m

# base memory per for 1 browser
crawler_memory: 1100Mi

# use local images built to :latest tag
backend_image: docker.io/webrecorder/browsertrix-backend:latest
frontend_image: docker.io/webrecorder/browsertrix-frontend:latest

backend_pull_policy: "Never"
frontend_pull_policy: "Never"

default_crawl_filename_template: "@ts-testing-@hostsuffix.wacz"

operator_resync_seconds: 3

mongo_auth:
  # specify either username + password (for local mongo)
  username: root
  password: PASSWORD@


superuser:
  # set this to enable a superuser admin
  email: admin@example.com

  # optional: if not set, automatically generated
  # change or remove this
  password: PASSW0RD!


local_service_port: 30870

# test max pages per crawl global limit
max_pages_per_crawl: 4

registration_enabled: "0"

# log failed crawl pods to operator backend
log_failed_crawl_lines: 200
